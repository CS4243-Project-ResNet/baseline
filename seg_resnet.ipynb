{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7fa2873e62e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from math import floor\n",
    "import cv2\n",
    "\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/t/tianqi/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-11-10 Python-3.8.10 torch-1.12.1+cu102 CUDA:0 (NVIDIA TITAN RTX, 24220MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n",
      "Using cache found in /home/t/tianqi/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-11-10 Python-3.8.10 torch-1.12.1+cu102 CUDA:0 (NVIDIA TITAN RTX, 24220MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "gun_model = torch.hub.load('ultralytics/yolov5', 'custom', path='/home/t/tianqi/CS4243_proj/my_utils/best1110.pt')\n",
    "gun_model.conf = 0.1\n",
    "knife_model = torch.hub.load('ultralytics/yolov5', 'custom', path='/home/t/tianqi/CS4243_proj/my_utils/knife_best.pt')\n",
    "knife_model.conf = 0.1\n",
    "\n",
    "def get_classifcation_bounding_box(file_path, model, asize):\n",
    "    results = model(file_path, size=asize)\n",
    "\n",
    "    objects = []\n",
    "    for obj in results.xyxy[0]:\n",
    "        objects.append(\n",
    "            {\n",
    "                \"class\": int(obj[5]), \n",
    "                \"xmin\": float(obj[0]),\n",
    "                \"ymin\": float(obj[1]),\n",
    "                \"xmax\": float(obj[2]),\n",
    "                \"ymax\": float(obj[3]),\n",
    "            })\n",
    "    return objects\n",
    "\n",
    "def detect_overlap(mask, xmin, xmax, ymin, ymax):\n",
    "    return np.count_nonzero(mask[ymin:ymax, xmin:xmax]) > 0\n",
    "\n",
    "def get_seg_file(img_path):\n",
    "    paths = img_path.split('/')\n",
    "    paths[0] = \"seg\"\n",
    "    seg_dir = '/'.join(paths)\n",
    "    im_read = cv2.imread(seg_dir, 0)\n",
    "    return im_read\n",
    "\n",
    "def get_seg_bin(img_path, thres=50):\n",
    "    seg = get_seg_file(img_path)\n",
    "    ret, mask = cv2.threshold(seg, thres, 1, cv2.THRESH_BINARY)\n",
    "    return mask\n",
    "\n",
    "count = 0\n",
    "def combine_mask_bounding_box(file_path, mask_thres, box_thres):\n",
    "    global count\n",
    "    gun_boxes = get_classifcation_bounding_box(file_path, gun_model, 540)\n",
    "    knife_boxes = get_classifcation_bounding_box(file_path, knife_model, 640)\n",
    "    count += len(knife_boxes)\n",
    "\n",
    "    boxes = gun_boxes + knife_boxes\n",
    "    mask = get_seg_bin(file_path, thres=mask_thres)\n",
    "    r, c = mask.shape\n",
    "\n",
    "    for box in boxes:\n",
    "        xmin, xmax, ymin, ymax = floor(box[\"xmin\"]), floor(box[\"xmax\"]), floor(box[\"ymin\"]), floor(box[\"ymax\"])\n",
    "        if detect_overlap(mask, xmin, xmax, ymin, ymax):\n",
    "            mask[max(0, ymin-box_thres):min(ymax+box_thres, r), max(0, xmin-box_thres):min(xmax+box_thres, c)] = 1\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.segs = []\n",
    "        self.labels = []\n",
    "        self.__preprocess__()\n",
    "\n",
    "\n",
    "    def __preprocess__(self):\n",
    "        subfolders = ['carrying', 'normal', 'threat']\n",
    "        for i in range(len(subfolders)):\n",
    "            # print(subfolders[i])\n",
    "            files = os.listdir(os.path.join(self.root_dir, subfolders[i]))\n",
    "            for f in files:\n",
    "                img_path = os.path.join(self.root_dir, subfolders[i], f)\n",
    "                mask = combine_mask_bounding_box(img_path, 0, 50)\n",
    "                img = cv2.imread(img_path)\n",
    "\n",
    "                seg_img = cv2.bitwise_and(img, img, mask = mask)\n",
    "\n",
    "                self.segs.append(seg_img)\n",
    "                self.labels.append(i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.segs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = self.segs[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "\n",
    "data_dir = 'data'\n",
    "image_datasets = {x: SegDataset(os.path.join(data_dir, x), transform=data_transforms)\n",
    "                  for x in ['train', 'val', 'test']}\n",
    "\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "# class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='NVIDIA TITAN RTX', major=7, minor=5, total_memory=24220MB, multi_processor_count=72)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(torch.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 3)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "learning_rate = 0.0004\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004\n",
      "Epoch 0/39\n",
      "----------\n",
      "train Loss: 1.1068 Acc: 0.3944\n",
      "val Loss: 1.2990 Acc: 0.4252\n",
      "test Loss: 1.3504 Acc: 0.4158\n",
      "\n",
      "Epoch 1/39\n",
      "----------\n",
      "train Loss: 0.9970 Acc: 0.4962\n",
      "val Loss: 0.8278 Acc: 0.6168\n",
      "test Loss: 0.8452 Acc: 0.6105\n",
      "\n",
      "Epoch 2/39\n",
      "----------\n",
      "train Loss: 0.8463 Acc: 0.6041\n",
      "val Loss: 0.7360 Acc: 0.6772\n",
      "test Loss: 0.7924 Acc: 0.6053\n",
      "\n",
      "Epoch 3/39\n",
      "----------\n",
      "train Loss: 0.7288 Acc: 0.6863\n",
      "val Loss: 0.8824 Acc: 0.6352\n",
      "test Loss: 0.7462 Acc: 0.6947\n",
      "\n",
      "Epoch 4/39\n",
      "----------\n",
      "train Loss: 0.6026 Acc: 0.7293\n",
      "val Loss: 0.7111 Acc: 0.7087\n",
      "test Loss: 0.6858 Acc: 0.6895\n",
      "\n",
      "Epoch 5/39\n",
      "----------\n",
      "train Loss: 0.5456 Acc: 0.7911\n",
      "val Loss: 0.6378 Acc: 0.7270\n",
      "test Loss: 0.6875 Acc: 0.7316\n",
      "\n",
      "Epoch 6/39\n",
      "----------\n",
      "train Loss: 0.4977 Acc: 0.8069\n",
      "val Loss: 0.5682 Acc: 0.7638\n",
      "test Loss: 0.5785 Acc: 0.7895\n",
      "\n",
      "Epoch 7/39\n",
      "----------\n",
      "train Loss: 0.3519 Acc: 0.8620\n",
      "val Loss: 0.4974 Acc: 0.8084\n",
      "test Loss: 0.5091 Acc: 0.7895\n",
      "\n",
      "Epoch 8/39\n",
      "----------\n",
      "train Loss: 0.3258 Acc: 0.8899\n",
      "val Loss: 0.4900 Acc: 0.8031\n",
      "test Loss: 0.4683 Acc: 0.8211\n",
      "\n",
      "Epoch 9/39\n",
      "----------\n",
      "train Loss: 0.2906 Acc: 0.8944\n",
      "val Loss: 0.4935 Acc: 0.8163\n",
      "test Loss: 0.4485 Acc: 0.8053\n",
      "\n",
      "Epoch 10/39\n",
      "----------\n",
      "train Loss: 0.2267 Acc: 0.9306\n",
      "val Loss: 0.4790 Acc: 0.8215\n",
      "test Loss: 0.4727 Acc: 0.8053\n",
      "\n",
      "Epoch 11/39\n",
      "----------\n",
      "train Loss: 0.2500 Acc: 0.9133\n",
      "val Loss: 0.4866 Acc: 0.8320\n",
      "test Loss: 0.4316 Acc: 0.8211\n",
      "\n",
      "Epoch 12/39\n",
      "----------\n",
      "train Loss: 0.2166 Acc: 0.9268\n",
      "val Loss: 0.5225 Acc: 0.8136\n",
      "test Loss: 0.5445 Acc: 0.7737\n",
      "\n",
      "Epoch 13/39\n",
      "----------\n",
      "train Loss: 0.2146 Acc: 0.9291\n",
      "val Loss: 0.5194 Acc: 0.8110\n",
      "test Loss: 0.5753 Acc: 0.7579\n",
      "\n",
      "Epoch 14/39\n",
      "----------\n",
      "train Loss: 0.2263 Acc: 0.9238\n",
      "val Loss: 0.5007 Acc: 0.8268\n",
      "test Loss: 0.4437 Acc: 0.8263\n",
      "\n",
      "Epoch 15/39\n",
      "----------\n",
      "train Loss: 0.1923 Acc: 0.9314\n",
      "val Loss: 0.5316 Acc: 0.8110\n",
      "test Loss: 0.4594 Acc: 0.8316\n",
      "\n",
      "Epoch 16/39\n",
      "----------\n",
      "train Loss: 0.2163 Acc: 0.9299\n",
      "val Loss: 0.4926 Acc: 0.8189\n",
      "test Loss: 0.4726 Acc: 0.8053\n",
      "\n",
      "Epoch 17/39\n",
      "----------\n",
      "train Loss: 0.1957 Acc: 0.9359\n",
      "val Loss: 0.4916 Acc: 0.8373\n",
      "test Loss: 0.5092 Acc: 0.8000\n",
      "\n",
      "Epoch 18/39\n",
      "----------\n",
      "train Loss: 0.2107 Acc: 0.9291\n",
      "val Loss: 0.4768 Acc: 0.8373\n",
      "test Loss: 0.4579 Acc: 0.8316\n",
      "\n",
      "Epoch 19/39\n",
      "----------\n",
      "train Loss: 0.1919 Acc: 0.9412\n",
      "val Loss: 0.4824 Acc: 0.8294\n",
      "test Loss: 0.4986 Acc: 0.8158\n",
      "\n",
      "Epoch 20/39\n",
      "----------\n",
      "train Loss: 0.1943 Acc: 0.9336\n",
      "val Loss: 0.4921 Acc: 0.8215\n",
      "test Loss: 0.4528 Acc: 0.8158\n",
      "\n",
      "Epoch 21/39\n",
      "----------\n",
      "train Loss: 0.2163 Acc: 0.9276\n",
      "val Loss: 0.5072 Acc: 0.8189\n",
      "test Loss: 0.4805 Acc: 0.8316\n",
      "\n",
      "Epoch 22/39\n",
      "----------\n",
      "train Loss: 0.1909 Acc: 0.9382\n",
      "val Loss: 0.4849 Acc: 0.8346\n",
      "test Loss: 0.4372 Acc: 0.8421\n",
      "\n",
      "Epoch 23/39\n",
      "----------\n",
      "train Loss: 0.2305 Acc: 0.9231\n",
      "val Loss: 0.4766 Acc: 0.8241\n",
      "test Loss: 0.4495 Acc: 0.8263\n",
      "\n",
      "Epoch 24/39\n",
      "----------\n",
      "train Loss: 0.1920 Acc: 0.9336\n",
      "val Loss: 0.4812 Acc: 0.8268\n",
      "test Loss: 0.4331 Acc: 0.8158\n",
      "\n",
      "Epoch 25/39\n",
      "----------\n",
      "train Loss: 0.1989 Acc: 0.9382\n",
      "val Loss: 0.4626 Acc: 0.8189\n",
      "test Loss: 0.4585 Acc: 0.8105\n",
      "\n",
      "Epoch 26/39\n",
      "----------\n",
      "train Loss: 0.1862 Acc: 0.9382\n",
      "val Loss: 0.4946 Acc: 0.8346\n",
      "test Loss: 0.4253 Acc: 0.8474\n",
      "\n",
      "Epoch 27/39\n",
      "----------\n",
      "train Loss: 0.1897 Acc: 0.9434\n",
      "val Loss: 0.4706 Acc: 0.8294\n",
      "test Loss: 0.4879 Acc: 0.8000\n",
      "\n",
      "Epoch 28/39\n",
      "----------\n",
      "train Loss: 0.1956 Acc: 0.9397\n",
      "val Loss: 0.4676 Acc: 0.8268\n",
      "test Loss: 0.4833 Acc: 0.7737\n",
      "\n",
      "Epoch 29/39\n",
      "----------\n",
      "train Loss: 0.1880 Acc: 0.9419\n",
      "val Loss: 0.4459 Acc: 0.8346\n",
      "test Loss: 0.4191 Acc: 0.8368\n",
      "\n",
      "Epoch 30/39\n",
      "----------\n",
      "train Loss: 0.2062 Acc: 0.9359\n",
      "val Loss: 0.5551 Acc: 0.7848\n",
      "test Loss: 0.4874 Acc: 0.8000\n",
      "\n",
      "Epoch 31/39\n",
      "----------\n",
      "train Loss: 0.1827 Acc: 0.9510\n",
      "val Loss: 0.4619 Acc: 0.8346\n",
      "test Loss: 0.4110 Acc: 0.8263\n",
      "\n",
      "Epoch 32/39\n",
      "----------\n",
      "train Loss: 0.1821 Acc: 0.9442\n",
      "val Loss: 0.4925 Acc: 0.8346\n",
      "test Loss: 0.4486 Acc: 0.8421\n",
      "\n",
      "Epoch 33/39\n",
      "----------\n",
      "train Loss: 0.1907 Acc: 0.9449\n",
      "val Loss: 0.4831 Acc: 0.8110\n",
      "test Loss: 0.4431 Acc: 0.8316\n",
      "\n",
      "Epoch 34/39\n",
      "----------\n",
      "train Loss: 0.2003 Acc: 0.9419\n",
      "val Loss: 0.4734 Acc: 0.8346\n",
      "test Loss: 0.4320 Acc: 0.8263\n",
      "\n",
      "Epoch 35/39\n",
      "----------\n",
      "train Loss: 0.1827 Acc: 0.9419\n",
      "val Loss: 0.4559 Acc: 0.8320\n",
      "test Loss: 0.4020 Acc: 0.8632\n",
      "\n",
      "Epoch 36/39\n",
      "----------\n",
      "train Loss: 0.2016 Acc: 0.9397\n",
      "val Loss: 0.4620 Acc: 0.8399\n",
      "test Loss: 0.4432 Acc: 0.8474\n",
      "\n",
      "Epoch 37/39\n",
      "----------\n",
      "train Loss: 0.1983 Acc: 0.9359\n",
      "val Loss: 0.4601 Acc: 0.8425\n",
      "test Loss: 0.4298 Acc: 0.8421\n",
      "\n",
      "Epoch 38/39\n",
      "----------\n",
      "train Loss: 0.1962 Acc: 0.9397\n",
      "val Loss: 0.4565 Acc: 0.8373\n",
      "test Loss: 0.4670 Acc: 0.8053\n",
      "\n",
      "Epoch 39/39\n",
      "----------\n",
      "train Loss: 0.1830 Acc: 0.9502\n",
      "val Loss: 0.4732 Acc: 0.8346\n",
      "test Loss: 0.4337 Acc: 0.8316\n",
      "\n",
      "Training complete in 33m 53s\n",
      "Best val Acc: 0.842520\n"
     ]
    }
   ],
   "source": [
    "print(learning_rate)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), \"seg_resnet50_01.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85        79\n",
      "           1       0.85      0.81      0.83        43\n",
      "           2       0.89      0.79      0.84        68\n",
      "\n",
      "    accuracy                           0.84       190\n",
      "   macro avg       0.85      0.84      0.84       190\n",
      "weighted avg       0.85      0.84      0.84       190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "model_ft.eval()\n",
    "\n",
    "for inputs, labels in dataloaders[\"test\"]:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    outputs = model_ft(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    y_pred.extend(preds.data.cpu())\n",
    "    y_true.extend(labels.data.cpu())\n",
    "\n",
    "\n",
    "print(classification_report(y_true, y_pred, labels=[0,1,2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
